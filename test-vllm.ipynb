{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "client = OpenAI(base_url=\"http://0.0.0.0:8000/v1\", api_key=\"sk-xxx\") # dummy key\n",
    "\n",
    "\n",
    "def get_response(name, max_tokens = 100):\n",
    "    t0 = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        max_tokens=max_tokens,\n",
    "        model=\"can-write-anything-here\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a story writing assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Write a story about llamas.\"\n",
    "            }\n",
    "        ])\n",
    "    return name, response, time.time() - t0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "t0 = time.time()\n",
    "threads = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    # Submit the tasks to the executor\n",
    "    for i in range(10):\n",
    "        threads.append(executor.submit(get_response, i))\n",
    "        print('Submited thread', i)\n",
    "\n",
    "    # print results as and when they come in\n",
    "    for task in concurrent.futures.as_completed(threads):\n",
    "        name, response, exec_time = task.result()\n",
    "        message = response.choices[0].message.content\n",
    "        print(f'Request {name}, time: {exec_time:.2f}, n_tokens = {response.usage.total_tokens}')\n",
    "        #print(message)\n",
    "\n",
    "print('Total Execution time:', time.time()-t0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
